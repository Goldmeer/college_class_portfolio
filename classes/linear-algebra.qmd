---
title: "Linear Algebra"
format:
  html:
    toc: true
    code-fold: true
---

# Overview

Linear Algebra is a core mathematical discipline that studies vectors, matrices, and linear transformations.  
It forms the theoretical foundation for **machine learning**, **data analysis**, **optimization**, and **computer graphics**.  
This page outlines the major concepts from my Linear Algebra coursework and demonstrates my competency through examples and applied mini-projects.

---

# Why Linear Algebra Matters in Business Analytics

Linear Algebra is one of the most important subjects for anyone working in:

- Machine learning  
- Optimization and operations research  
- Statistical modeling  
- Data engineering  
- Econometrics  
- Business forecasting  

Key reasons:

- Many ML models **are** matrix equations.  
- PCA, SVD, and dimensionality reduction depend entirely on eigenvalues.  
- Linear systems model supply chains, finance, and economic relationships.  
- Optimization algorithms rely on gradients, matrices, and vector operations.

---

# Core Topics Covered

## 1. Vectors and Vector Operations
- Scalar multiplication  
- Vector addition  
- Dot product  
- Norms and distances  
- Projections  

## 2. Matrices
- Matrix addition and multiplication  
- Identity and inverse matrices  
- Determinants and rank  
- Subspaces: column space, null space  

## 3. Solving Linear Systems
- Gaussian elimination  
- Reduced row echelon form  
- Matrix equation \( A\mathbf{x} = \mathbf{b} \)  
- Existence and uniqueness of solutions  

## 4. Eigenvalues and Eigenvectors
- Characteristic polynomial  
- Diagonalization  
- Applications to:
  - Markov chains  
  - PCA  
  - Stability in economics  

## 5. Orthogonality
- Orthogonal vectors  
- Orthogonal projections  
- Gram-Schmidt process  
- QR factorization  

## 6. Singular Value Decomposition (SVD)
- Connection to PCA  
- Low-rank approximation  
- Noise reduction and compression  

---

# Demonstrations of Competency

Below are sample demonstrations that illustrate core Linear Algebra skills using LaTeX.

---

## Example 1 — Solving a System of Equations

Solve the system:

\[
\begin{cases}
2x + y - z = 1 \\
-x + 3y + 2z = 12 \\
3x + y + z = 7
\end{cases}
\]

Matrix form:

\[
A\mathbf{x} = \mathbf{b}
\quad\text{where}\quad
A = 
\begin{pmatrix}
2 & 1 & -1 \\
-1 & 3 & 2 \\
3 & 1 & 1
\end{pmatrix},
\quad
\mathbf{b} =
\begin{pmatrix}
1 \\ 12 \\ 7
\end{pmatrix}
\]

**Solution (Gaussian elimination):**

\[
\mathbf{x} =
\begin{pmatrix}
2 \\ 3 \\ 1
\end{pmatrix}
\]

---

## Example 2 — Eigenvalue Problem

Given matrix

\[
A =
\begin{pmatrix}
4 & 1 \\
2 & 3
\end{pmatrix}
\]

The characteristic polynomial:

\[
\det(A - \lambda I)
= \lambda^2 - 7\lambda + 10
\]

Eigenvalues:

\[
\lambda_1 = 5,\qquad \lambda_2 = 2
\]

Eigenvectors:

\[
v_1 =
\begin{pmatrix}
1 \\ 1
\end{pmatrix},
\qquad
v_2=
\begin{pmatrix}
1 \\ -2
\end{pmatrix}
\]

---

# Applied Mini-Project: PCA on a Simple Dataset

Principal Component Analysis (PCA) is a dimensionality reduction technique based entirely on:

- Covariance matrices  
- Eigenvalues  
- Eigenvectors  

### Steps Demonstrated
1. Construct covariance matrix  
2. Compute eigenvalues/eigenvectors  
3. Interpret principal components  
4. Explain variance captured  

### Example Covariance Matrix

\[
C =
\begin{pmatrix}
2.0 & 0.8 \\
0.8 & 0.6
\end{pmatrix}
\]

Eigenvalues:

\[
\lambda_1 = 2.5,\qquad \lambda_2 = 0.1
\]

Interpretation:

- First principal component explains ~96% of variance  
- Second component explains ~4%  

### Visual Explanation
This analysis shows how linear algebra is used to compress data from 2D → 1D while retaining most information.

---

# Reflection on Learning

Taking Linear Algebra significantly strengthened my:

- Abstract reasoning  
- Understanding of vector spaces  
- Ability to interpret ML model mechanics  
- Analytical problem-solving skills  

The course provided the mathematical backbone for all future analytics, modeling, and machine learning coursework.

---

# Additional Resources
- *Linear Algebra and Its Applications* — Lay, Lay & McDonald  
- *Introduction to Linear Algebra* — Gilbert Strang  
- 3Blue1Brown “Essence of Linear Algebra” series

